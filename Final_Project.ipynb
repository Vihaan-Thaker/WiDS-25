{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1197fab-9bd3-4b3c-aca4-b60c9c4a864a",
   "metadata": {},
   "source": [
    "#### Inputting the required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "90013b89-aec8-4ac5-89c0-91c269c6c411",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yfinance as yf\n",
    "from datetime import datetime, time\n",
    "import pytz\n",
    "import ta\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import requests\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78acc97e-9de6-42a9-8b3a-2dcb08fafae9",
   "metadata": {},
   "source": [
    "#### Inputing the market data from Yahoo Finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0b3af5c3-9e70-40e6-9e62-d15aea70bb1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zp/_z5ytlrj39x9_lyt_g51rrfm0000gn/T/ipykernel_82860/3049154687.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df = yf.download(ticker, period=\"2y\")\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "ticker = 'ADANIPOWER.NS'\n",
    "df = yf.download(ticker, period=\"2y\")\n",
    "\n",
    "if isinstance(df.columns, pd.MultiIndex): # Flattening multi level columns\n",
    "    df.columns = df.columns.get_level_values(0)\n",
    "\n",
    "df['Close'] = df['Close'].squeeze() # Ensure Close is 1D Series\n",
    "df['Volume'] = df['Volume'].squeeze()\n",
    "\n",
    "\n",
    "df['log_return'] = np.log(df['Close'] / df['Close'].shift(1))\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d26e33-ed8c-4bb8-8d79-ac4df783d898",
   "metadata": {},
   "source": [
    "#### Deriving the values for the Technical Indicators from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "421ab933-8dfb-4266-b8ca-603eccf27c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rsi'] = ta.momentum.RSIIndicator(df['Close']).rsi()\n",
    "macd = ta.trend.MACD(df['Close'])\n",
    "df['macd'] = macd.macd()\n",
    "df['volatility'] = df['log_return'].rolling(12).std()\n",
    "df['vol_chg'] = df['Volume'].pct_change()\n",
    "\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb6d11d-450b-4433-9b08-4f0fc4b9778e",
   "metadata": {},
   "source": [
    "#### Setting Up FinBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2097d63e-579c-4c63-8e1f-38995e928422",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('ProsusAI/finbert')\n",
    "model = BertForSequenceClassification.from_pretrained('ProsusAI/finbert')\n",
    "model.eval()\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4353311c-89d3-4f8b-97cb-29b17faf11af",
   "metadata": {},
   "source": [
    "#### TimeZone Handling for the news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8aa7e45e-d28f-4aee-85a5-96f285d3fa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "IST = pytz.timezone(\"Asia/Kolkata\")\n",
    "MARKET_CLOSE = time(15, 30)\n",
    "\n",
    "def map_to_trading_day(ts):\n",
    "    if ts.weekday() >= 5:\n",
    "        ts += pd.offsets.BDay()\n",
    "    if ts.time() > MARKET_CLOSE:\n",
    "        ts += pd.offsets.BDay()\n",
    "    return pd.Timestamp(ts.date())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a9648d-6ded-4543-8bd9-d4d74ce30c7a",
   "metadata": {},
   "source": [
    "#### Fetching the news from NEWS Api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cdad27eb-7338-44e0-85d7-8f4081517870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching news from 2024-02-25 to 2024-03-26\n",
      "Fetching news from 2024-03-27 to 2024-04-26\n",
      "Fetching news from 2024-04-27 to 2024-05-27\n",
      "Fetching news from 2024-05-28 to 2024-06-27\n",
      "Fetching news from 2024-06-28 to 2024-07-28\n",
      "Fetching news from 2024-07-29 to 2024-08-28\n",
      "Fetching news from 2024-08-29 to 2024-09-28\n",
      "Fetching news from 2024-09-29 to 2024-10-29\n",
      "Fetching news from 2024-10-30 to 2024-11-29\n",
      "Fetching news from 2024-11-30 to 2024-12-30\n",
      "Fetching news from 2024-12-31 to 2025-01-30\n",
      "Fetching news from 2025-01-31 to 2025-03-02\n",
      "Fetching news from 2025-03-03 to 2025-04-02\n",
      "Fetching news from 2025-04-03 to 2025-05-03\n",
      "Fetching news from 2025-05-04 to 2025-06-03\n",
      "Fetching news from 2025-06-04 to 2025-07-04\n",
      "Fetching news from 2025-07-05 to 2025-08-04\n",
      "Fetching news from 2025-08-05 to 2025-09-04\n",
      "Fetching news from 2025-09-05 to 2025-10-05\n",
      "Fetching news from 2025-10-06 to 2025-11-05\n",
      "Fetching news from 2025-11-06 to 2025-12-06\n",
      "Fetching news from 2025-12-07 to 2026-01-06\n",
      "Fetching news from 2026-01-07 to 2026-01-30\n",
      "Total headlines: 100\n"
     ]
    }
   ],
   "source": [
    "NEWS_API_KEY = \"93298ff83d9045a8ac42d4100b517856\"\n",
    "query = 'Adani'\n",
    "\n",
    "start_date = (df.index.min() - pd.Timedelta(days=10)).date() # We go a few days eariler to avoid losing initial signal\n",
    "end_date = datetime.today().date()\n",
    "\n",
    "all_articles = []\n",
    "current = start_date\n",
    "\n",
    "while current <= end_date:\n",
    "    next_date = min(current + timedelta(days=30), end_date)\n",
    "\n",
    "    print(f\"Fetching news from {current} to {next_date}\")\n",
    "\n",
    "    url = \"https://newsapi.org/v2/everything\"\n",
    "    params = {\n",
    "        \"q\": query,\n",
    "        \"from\": current.isoformat(),\n",
    "        \"to\": next_date.isoformat(),\n",
    "        \"language\": \"en\",\n",
    "        \"sortBy\": \"publishedAt\",\n",
    "        \"pageSize\": 100,\n",
    "        \"apiKey\": NEWS_API_KEY\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params=params)\n",
    "    articles = response.json().get(\"articles\", [])\n",
    "\n",
    "    for art in articles:\n",
    "        if art[\"title\"] and art[\"publishedAt\"]:\n",
    "            all_articles.append({\n",
    "                \"headline\": art[\"title\"],\n",
    "                \"timestamp_utc\": art[\"publishedAt\"]\n",
    "            })\n",
    "\n",
    "    current = next_date + timedelta(days=1)\n",
    "\n",
    "news_df = pd.DataFrame(all_articles)\n",
    "news_df = pd.DataFrame(all_articles)\n",
    "\n",
    "if len(news_df) == 0:\n",
    "    print(\"⚠ No news fetched. Check API limits or date range.\")\n",
    "else:\n",
    "    news_df['timestamp_utc'] = pd.to_datetime(news_df['timestamp_utc'], utc=True)\n",
    "\n",
    "print(\"Total headlines:\", len(news_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d3cb61-d936-4f03-a248-a7dd281b2496",
   "metadata": {},
   "source": [
    "#### Now that we have obtained the data, we will align it according to the trade day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0544b7d6-b0c8-466e-aa48-c9df1cad4e77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp_ist</th>\n",
       "      <th>trading_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2026-01-29 15:17:19+05:30</td>\n",
       "      <td>2026-01-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2026-01-29 14:11:51+05:30</td>\n",
       "      <td>2026-01-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2026-01-29 13:37:23+05:30</td>\n",
       "      <td>2026-01-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2026-01-29 13:23:00+05:30</td>\n",
       "      <td>2026-01-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2026-01-29 10:38:59+05:30</td>\n",
       "      <td>2026-01-29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              timestamp_ist trading_day\n",
       "0 2026-01-29 15:17:19+05:30  2026-01-29\n",
       "1 2026-01-29 14:11:51+05:30  2026-01-29\n",
       "2 2026-01-29 13:37:23+05:30  2026-01-29\n",
       "3 2026-01-29 13:23:00+05:30  2026-01-29\n",
       "4 2026-01-29 10:38:59+05:30  2026-01-29"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df['timestamp_utc'] = pd.to_datetime(news_df['timestamp_utc'], utc=True)\n",
    "news_df['timestamp_ist'] = news_df['timestamp_utc'].dt.tz_convert(IST)\n",
    "news_df['trading_day'] = news_df['timestamp_ist'].apply(map_to_trading_day)\n",
    "\n",
    "news_df[['timestamp_ist','trading_day']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fe4e35-c21a-429e-ab66-600e8bb15e2b",
   "metadata": {},
   "source": [
    "#### Now Loading FinBERT to get sentiment on the headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6115c98e-942b-4b3a-b90a-502698ee2a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_sentiment(texts):\n",
    "    inputs = tokenizer(texts, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    probs = F.softmax(outputs.logits, dim=1)\n",
    "    return (probs[:,0] - probs[:,1]).cpu().numpy()  # pos - neg\n",
    "\n",
    "batch_size = 32\n",
    "sentiments = []\n",
    "\n",
    "for i in range(0, len(news_df), batch_size):\n",
    "    batch_texts = news_df['headline'].iloc[i:i+batch_size].tolist()\n",
    "    sentiments.extend(get_batch_sentiment(batch_texts))\n",
    "\n",
    "news_df['sentiment'] = sentiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e16a88-9272-4c22-9ca9-6fb50e7b9bcd",
   "metadata": {},
   "source": [
    "#### Now aggregating daily headlines and their sentiment classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ddcd18a9-5c81-44b6-9aa7-23f024f799b7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zp/_z5ytlrj39x9_lyt_g51rrfm0000gn/T/ipykernel_82860/1082535320.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['sentiment'].fillna(0, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-03-07</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-08</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-11</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-12</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-13</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-14</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-15</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-18</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-19</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-20</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-21</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-22</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-25</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-26</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-27</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-28</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-01</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-02</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-03</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-04</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            sentiment\n",
       "Date                 \n",
       "2024-03-07        0.0\n",
       "2024-03-08        0.0\n",
       "2024-03-11        0.0\n",
       "2024-03-12        0.0\n",
       "2024-03-13        0.0\n",
       "2024-03-14        0.0\n",
       "2024-03-15        0.0\n",
       "2024-03-18        0.0\n",
       "2024-03-19        0.0\n",
       "2024-03-20        0.0\n",
       "2024-03-21        0.0\n",
       "2024-03-22        0.0\n",
       "2024-03-25        0.0\n",
       "2024-03-26        0.0\n",
       "2024-03-27        0.0\n",
       "2024-03-28        0.0\n",
       "2024-04-01        0.0\n",
       "2024-04-02        0.0\n",
       "2024-04-03        0.0\n",
       "2024-04-04        0.0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_sentiment = news_df.groupby('trading_day')['sentiment'].mean()\n",
    "\n",
    "df = df.merge(daily_sentiment, left_index=True, right_index=True, how='left')\n",
    "df['sentiment'].fillna(0, inplace=True)\n",
    "\n",
    "df[['sentiment']].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aecadc3-d89e-4be4-9b74-bc4451a907be",
   "metadata": {},
   "source": [
    "#### Preparing the data to be fed into the LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8c36f6d8-da03-4304-8d0c-40a1db06bf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'] = (df['log_return'].shift(-1) > 0).astype(int)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "features = ['log_return', 'rsi', 'macd', 'volatility', 'vol_chg', 'sentiment']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df[features] = scaler.fit_transform(df[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d19857a0-0dff-4161-8c23-3c53ed2056cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 60\n",
    "\n",
    "class MarketDataset(Dataset):\n",
    "    def __init__(self, data, features):\n",
    "        self.X = data[features].values\n",
    "        self.y = data['target'].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X) - SEQ_LEN\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            torch.tensor(self.X[idx:idx+SEQ_LEN], dtype=torch.float32),\n",
    "            torch.tensor(self.y[idx+SEQ_LEN], dtype=torch.float32)\n",
    "        )\n",
    "\n",
    "dataset = MarketDataset(df, features)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "train_ds, val_ds = torch.utils.data.random_split(dataset, [train_size, len(dataset)-train_size])\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a22b06-ce55-49f4-88cb-9b4a74bb92bd",
   "metadata": {},
   "source": [
    "#### Making the LSTM Model for classification whether stock should move up or down on the next day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "335ca41d-05a5-4f9c-9c80-2412bed97481",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, dropout=0.2)\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = out[:, -1, :]\n",
    "        return torch.sigmoid(self.fc(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "30221360-ea84-47fd-8347-2aa6dad989bb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: hidden=32, layers=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation IC: 0.1235\n",
      "\n",
      "Training model: hidden=32, layers=2\n",
      "Validation IC: 0.1231\n",
      "\n",
      "Training model: hidden=32, layers=3\n",
      "Validation IC: 0.0704\n",
      "\n",
      "Training model: hidden=64, layers=1\n",
      "Validation IC: 0.1430\n",
      "\n",
      "Training model: hidden=64, layers=2\n",
      "Validation IC: 0.1408\n",
      "\n",
      "Training model: hidden=64, layers=3\n",
      "Validation IC: 0.1500\n",
      "\n",
      "Training model: hidden=128, layers=1\n",
      "Validation IC: 0.0944\n",
      "\n",
      "Training model: hidden=128, layers=2\n",
      "Validation IC: 0.1560\n",
      "\n",
      "Training model: hidden=128, layers=3\n",
      "Validation IC: 0.1805\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def compute_ic(model, loader):\n",
    "    model.eval()\n",
    "    preds_all, targets_all = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            preds = model(X_batch).squeeze().cpu().numpy()\n",
    "            preds_all.extend(preds)\n",
    "            targets_all.extend(y_batch.numpy())\n",
    "\n",
    "    return np.corrcoef(preds_all, targets_all)[0,1]\n",
    "\n",
    "def train_model(hidden_dim, num_layers):\n",
    "    model = LSTMClassifier(len(features), hidden_dim, num_layers).to(device)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(15):  # shorter training for grid search\n",
    "        model.train()\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device).unsqueeze(1)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(X_batch)\n",
    "            loss = criterion(preds, y_batch)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "    val_ic = compute_ic(model, val_loader)\n",
    "    return model, val_ic\n",
    "\n",
    "hidden_options = [32, 64, 128]\n",
    "layer_options = [1, 2, 3]\n",
    "\n",
    "results = []\n",
    "\n",
    "for h in hidden_options:\n",
    "    for l in layer_options:\n",
    "        print(f\"Training model: hidden={h}, layers={l}\")\n",
    "        model, ic = train_model(h, l)\n",
    "        results.append((h, l, ic))\n",
    "        print(f\"Validation IC: {ic:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e52d2126-df2c-4058-9bc5-088ce9856041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Architecture:\n",
      "Hidden    128.000000\n",
      "Layers      3.000000\n",
      "IC          0.180477\n",
      "Name: 8, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results, columns=['Hidden', 'Layers', 'IC'])\n",
    "best_row = results_df.loc[results_df['IC'].idxmax()]\n",
    "\n",
    "print(\"Best Architecture:\")\n",
    "print(best_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a914726f-ada8-4d44-9cf6-45caf1b74e39",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.6964\n",
      "Epoch 2, Loss: 0.6932\n",
      "Epoch 3, Loss: 0.6898\n",
      "Epoch 4, Loss: 0.6880\n",
      "Epoch 5, Loss: 0.6788\n",
      "Epoch 6, Loss: 0.6797\n",
      "Epoch 7, Loss: 0.6732\n",
      "Epoch 8, Loss: 0.6709\n",
      "Epoch 9, Loss: 0.6588\n",
      "Epoch 10, Loss: 0.6575\n",
      "Epoch 11, Loss: 0.6595\n",
      "Epoch 12, Loss: 0.6530\n",
      "Epoch 13, Loss: 0.6459\n",
      "Epoch 14, Loss: 0.6395\n",
      "Epoch 15, Loss: 0.6348\n",
      "Epoch 16, Loss: 0.6267\n",
      "Epoch 17, Loss: 0.6478\n",
      "Epoch 18, Loss: 0.6197\n",
      "Epoch 19, Loss: 0.6038\n",
      "Epoch 20, Loss: 0.5961\n",
      "Epoch 21, Loss: 0.6129\n",
      "Epoch 22, Loss: 0.6079\n",
      "Epoch 23, Loss: 0.6106\n",
      "Epoch 24, Loss: 0.5930\n",
      "Epoch 25, Loss: 0.5757\n",
      "Epoch 26, Loss: 0.5548\n",
      "Epoch 27, Loss: 0.5477\n",
      "Epoch 28, Loss: 0.5582\n",
      "Epoch 29, Loss: 0.5255\n",
      "Epoch 30, Loss: 0.5256\n",
      "Epoch 31, Loss: 0.4882\n",
      "Epoch 32, Loss: 0.4910\n",
      "Epoch 33, Loss: 0.4703\n",
      "Epoch 34, Loss: 0.4548\n",
      "Epoch 35, Loss: 0.4432\n",
      "Epoch 36, Loss: 0.4282\n",
      "Epoch 37, Loss: 0.4206\n",
      "Epoch 38, Loss: 0.4058\n",
      "Epoch 39, Loss: 0.3621\n",
      "Epoch 40, Loss: 0.3387\n"
     ]
    }
   ],
   "source": [
    "best_hidden = int(best_row['Hidden'])\n",
    "best_layers = int(best_row['Layers'])\n",
    "\n",
    "best_model = LSTMClassifier(len(features), best_hidden, best_layers).to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(best_model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(40):\n",
    "    best_model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device).unsqueeze(1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        preds = best_model(X_batch)\n",
    "        loss = criterion(preds, y_batch)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(best_model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4aba6042-4e49-481d-8f0a-f6ed3ba5820b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation\n",
      "---------------------\n",
      "Accuracy     : 0.5476\n",
      "Precision    : 0.5882\n",
      "Recall       : 0.4545\n",
      "F1 Score     : 0.5128\n",
      "Information Coefficient (IC): 0.1224\n",
      "\n",
      "Confusion Matrix:\n",
      "[[26 14]\n",
      " [24 20]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5476190476190477,\n",
       " 0.5882352941176471,\n",
       " 0.45454545454545453,\n",
       " 0.5128205128205128,\n",
       " 0.12237172233308848)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "def evaluate_model(model, loader):\n",
    "    model.eval()\n",
    "    preds_all, targets_all = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            preds = model(X_batch).squeeze().cpu().numpy()\n",
    "            preds_all.extend(preds)\n",
    "            targets_all.extend(y_batch.numpy())\n",
    "\n",
    "    preds_all = np.array(preds_all)\n",
    "    targets_all = np.array(targets_all)\n",
    "\n",
    "    # Convert probabilities → class labels\n",
    "    pred_labels = (preds_all > 0.5).astype(int)\n",
    "\n",
    "    acc = accuracy_score(targets_all, pred_labels)\n",
    "    precision = precision_score(targets_all, pred_labels)\n",
    "    recall = recall_score(targets_all, pred_labels)\n",
    "    f1 = f1_score(targets_all, pred_labels)\n",
    "    ic = np.corrcoef(preds_all, targets_all)[0,1]\n",
    "    cm = confusion_matrix(targets_all, pred_labels)\n",
    "\n",
    "    print(\"Model Evaluation\")\n",
    "    print(\"---------------------\")\n",
    "    print(f\"Accuracy     : {acc:.4f}\")\n",
    "    print(f\"Precision    : {precision:.4f}\")\n",
    "    print(f\"Recall       : {recall:.4f}\")\n",
    "    print(f\"F1 Score     : {f1:.4f}\")\n",
    "    print(f\"Information Coefficient (IC): {ic:.4f}\")\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "    return acc, precision, recall, f1, ic\n",
    "\n",
    "evaluate_model(best_model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9de903c-b7ae-4cca-99cb-032314e90b7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
